{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "435b9265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92c3be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Files\n",
    "def load_data(dir_path):\n",
    "    '''\n",
    "        Function to Read Data from mat Files\n",
    "    '''\n",
    "    \n",
    "    mat_files = []\n",
    "    for m in os.listdir(dir_path):\n",
    "        if m.endswith('.mat'):\n",
    "            mat_files.append(m)\n",
    "    \n",
    "    data = {}\n",
    "    for sbj, file in enumerate(mat_files):\n",
    "        file_path = os.path.join(dir_path, file)\n",
    "        mat_data = scipy.io.loadmat(file_path)\n",
    "        data[sbj] = (mat_data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c2c8b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FilterBandPass(CNT, Wn, Fs):    \n",
    "    Wn = np.array([Wn[0] / (Fs/2), Wn[1] / (Fs/2)])\n",
    "    \n",
    "    # Filter Design\n",
    "    order = 3\n",
    "    type = 'bandpass'\n",
    "    b, a = scipy.signal.butter(order, Wn, btype = 'bandpass')\n",
    "    \n",
    "    # Apply Filter\n",
    "    CNT = scipy.signal.filtfilt(b, a, CNT, axis = 0)\n",
    "    \n",
    "    return CNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75c74a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAR Filter for Spatial Filtering\n",
    "def CARFilter(Data):\n",
    "    M = np.mean(Data, axis = 1)\n",
    "    \n",
    "    for i in range(Data.shape[1]):\n",
    "        Data[:, i] = Data[:, i] - M\n",
    "    \n",
    "    return Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f28ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSP(Train1, Train2, m):\n",
    "    Rh = 0\n",
    "    for i in range(Train1.shape[2]):\n",
    "        Data = Train1[:, :, i]\n",
    "\n",
    "        # Normalize Data\n",
    "        M = np.mean(Data, axis = 0)\n",
    "\n",
    "        for i in range(Data.shape[0]):\n",
    "            Data[i, :] = Data[i, :] - M\n",
    "\n",
    "        # Cov Matrix Calculation\n",
    "        Rh += Data.T @ Data / np.trace(Data.T @ Data)\n",
    "\n",
    "    Rf = 0\n",
    "    for i in range(Train2.shape[2]):\n",
    "        Data = Train2[:, :, i]\n",
    "\n",
    "        # Normalize Data\n",
    "        M = np.mean(Data, axis = 0)\n",
    "\n",
    "        for i in range(Data.shape[0]):\n",
    "            Data[i, :] = Data[i, :] - M\n",
    "\n",
    "        # Cov Matrix Calculation\n",
    "        Rf += Data.T @ Data / np.trace(Data.T @ Data)\n",
    "\n",
    "\n",
    "    # Normalize Cov Matrix\n",
    "    Rf /= Train2.shape[2]\n",
    "    Rh /= Train1.shape[2]\n",
    "\n",
    "    # Eigen Value Decomposition\n",
    "    u, v = scipy.linalg.eig(Rh, Rf)\n",
    "    # u = np.real(u)\n",
    "\n",
    "    # Sort eigenvalues and eigenvectors by eigenvalues\n",
    "    sorted_indices = np.argsort(u)[::-1]  # Sort in descending order\n",
    "    u = u[sorted_indices]\n",
    "    v = v[:, sorted_indices]\n",
    "\n",
    "    Wm = list(range(m)) + list(range(v.shape[1] - m, v.shape[1]))\n",
    "    W = v[:, Wm]\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b88a3706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RCSP(Train1, Train2, m, Alpha):\n",
    "    Rh = 0\n",
    "    for i in range(Train1.shape[2]):\n",
    "        Data = Train1[:, :, i]\n",
    "\n",
    "        # Normalize Data\n",
    "        M = np.mean(Data, axis = 0)\n",
    "\n",
    "        for i in range(Data.shape[0]):\n",
    "            Data[i, :] = Data[i, :] - M\n",
    "\n",
    "        # Cov Matrix Calculation\n",
    "        Rh += Data.T @ Data / np.trace(Data.T @ Data)\n",
    "\n",
    "    Rf = 0\n",
    "    for i in range(Train2.shape[2]):\n",
    "        Data = Train2[:, :, i]\n",
    "\n",
    "        # Normalize Data\n",
    "        M = np.mean(Data, axis = 0)\n",
    "\n",
    "        for i in range(Data.shape[0]):\n",
    "            Data[i, :] = Data[i, :] - M\n",
    "\n",
    "        # Cov Matrix Calculation\n",
    "        Rf += Data.T @ Data / np.trace(Data.T @ Data)\n",
    "\n",
    "\n",
    "    # Normalize Cov Matrix\n",
    "    Rf /= Train2.shape[2]\n",
    "    Rh /= Train1.shape[2]\n",
    "\n",
    "    R1 = Rh + Alpha * np.identity(Rh.shape[0])\n",
    "    R2 = Rf + Alpha * np.identity(Rh.shape[0])\n",
    "    \n",
    "    # Eigen Value Decomposition\n",
    "    u1, v1 = scipy.linalg.eig(Rh, R2)\n",
    "    # u = np.real(u)\n",
    "    \n",
    "    # Sort eigenvalues and eigenvectors by eigenvalues\n",
    "    sorted_indices = np.argsort(u1)[::-1]  # Sort in descending order\n",
    "    u1 = u1[sorted_indices]\n",
    "    v1 = v1[:, sorted_indices]\n",
    "    \n",
    "    \n",
    "    # Eigen Value Decomposition\n",
    "    u2, v2 = scipy.linalg.eig(Rf, R1)\n",
    "    # u = np.real(u)\n",
    "    \n",
    "    # Sort eigenvalues and eigenvectors by eigenvalues\n",
    "    sorted_indices = np.argsort(u2)[::-1]  # Sort in descending order\n",
    "    u2 = u2[sorted_indices]\n",
    "    v2 = v2[:, sorted_indices]\n",
    "    \n",
    "    W = np.concatenate((v1[:, :m], v2[:, :m]), axis = 1)\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ac64a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1\n",
      "Accuracy :  0.9  With Alpha of 1e-09\n",
      "Class 1 Accuracy : 90.0\n",
      "Class 2 Accuracy : 90.0\n",
      "Confusion Matrix : \n",
      " [[18  2]\n",
      " [ 2 18]]\n",
      "-----------------------------------------------------------------\n",
      "Subject 2\n",
      "Accuracy :  0.675  With Alpha of 0.0001\n",
      "Class 1 Accuracy : 70.0\n",
      "Class 2 Accuracy : 65.0\n",
      "Confusion Matrix : \n",
      " [[14  6]\n",
      " [ 7 13]]\n",
      "-----------------------------------------------------------------\n",
      "Subject 3\n",
      "Accuracy :  0.7  With Alpha of 1e-09\n",
      "Class 1 Accuracy : 70.0\n",
      "Class 2 Accuracy : 70.0\n",
      "Confusion Matrix : \n",
      " [[14  6]\n",
      " [ 6 14]]\n",
      "-----------------------------------------------------------------\n",
      "Subject 4\n",
      "Accuracy :  0.8  With Alpha of 1e-05\n",
      "Class 1 Accuracy : 75.0\n",
      "Class 2 Accuracy : 85.0\n",
      "Confusion Matrix : \n",
      " [[15  5]\n",
      " [ 3 17]]\n",
      "-----------------------------------------------------------------\n",
      "Subject 5\n",
      "Accuracy :  0.925  With Alpha of 0.001\n",
      "Class 1 Accuracy : 95.0\n",
      "Class 2 Accuracy : 90.0\n",
      "Confusion Matrix : \n",
      " [[19  1]\n",
      " [ 2 18]]\n",
      "-----------------------------------------------------------------\n",
      "Subject 6\n",
      "Accuracy :  0.925  With Alpha of 1e-07\n",
      "Class 1 Accuracy : 95.0\n",
      "Class 2 Accuracy : 90.0\n",
      "Confusion Matrix : \n",
      " [[19  1]\n",
      " [ 2 18]]\n",
      "-----------------------------------------------------------------\n",
      "Subject 7\n",
      "Accuracy :  0.875  With Alpha of 1e-05\n",
      "Class 1 Accuracy : 80.0\n",
      "Class 2 Accuracy : 95.0\n",
      "Confusion Matrix : \n",
      " [[16  4]\n",
      " [ 1 19]]\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dir_path = './Dataset'\n",
    "data = load_data(dir_path)\n",
    "np.random.seed(0)\n",
    "\n",
    "AvailbaleDataKeys = data.keys()\n",
    "# AvailbaleDataKeys = [6]\n",
    "\n",
    "for key in list(AvailbaleDataKeys):\n",
    "    \n",
    "    # Read Data\n",
    "    cnt = data[key]['cnt']\n",
    "    nfo = data[key]['nfo']\n",
    "    mrk = data[key]['mrk']\n",
    "    fs = nfo['fs'][0][0][0][0]\n",
    "    \n",
    "    ## Filtering Data\n",
    "    cnt = FilterBandPass(cnt, [8, 30], fs)\n",
    "    \n",
    "    # Spatial Filtering\n",
    "    cnt = CARFilter(cnt)\n",
    "    \n",
    "    # Trial Seperation\n",
    "    Ltr = 4 * fs\n",
    "    Pos = mrk['pos'][0][0][0]\n",
    "    Group = mrk['y'][0][0][0]\n",
    "    \n",
    "    data1 = np.zeros((Ltr, cnt.shape[1], len(Group)//2))\n",
    "    data2 = np.zeros((Ltr, cnt.shape[1], len(Group)//2))\n",
    "    c1 = 0\n",
    "    c2 = 0\n",
    "    \n",
    "    for i in range(len(Pos)):\n",
    "        Idx = range(Pos[i], Pos[i] + Ltr)\n",
    "        Trial = cnt[Idx, :]\n",
    "        \n",
    "        if Group[i] == 1:\n",
    "            data1[:, :, c1] = Trial\n",
    "            c1 += 1\n",
    "        elif Group[i] == -1:\n",
    "            data2[:, :, c2] = Trial\n",
    "            c2 += 1\n",
    "\n",
    "    ## Train and Test Data Separation\n",
    "    # Index Creation\n",
    "    TestDiv = 0.2\n",
    "    Idx = np.random.choice(data1.shape[2], size=int(TestDiv * data1.shape[2]), replace=False)\n",
    "    TestIdx = np.zeros(data1.shape[2], dtype=bool)\n",
    "    TestIdx[Idx] = True\n",
    "    \n",
    "    TrainIdx = ~TestIdx\n",
    "    \n",
    "    # Data Seperation\n",
    "    Train1 = data1[:, :, TrainIdx]\n",
    "    Train2 = data2[:, :, TrainIdx]\n",
    "    \n",
    "    Test1 = data1[:, :, TestIdx]\n",
    "    Test2 = data2[:, :, TestIdx]\n",
    "    \n",
    "    # CSP Weight Matrix Creation\n",
    "    M = 2\n",
    "    AlphaList = [10e-10, 10e-9, 10e-8, 10e-7, 10e-6, 10e-5, 10e-4, 10e-3, 10e-2, 10e-1]\n",
    "    \n",
    "    Accuracy = []\n",
    "    ConfMat = []\n",
    "    for Alpha in AlphaList:\n",
    "\n",
    "        W = RCSP(Train1, Train2, M, Alpha)\n",
    "\n",
    "\n",
    "        # Train Feature Extraction\n",
    "        Train = np.concatenate((Train1, Train2), axis = 2)    \n",
    "        FeatureTrain = np.zeros((2 * M, Train.shape[2]))\n",
    "\n",
    "        for i in range(Train.shape[2]):\n",
    "            tmp = Train[:, :, i].T\n",
    "            tmp = W.T @ tmp\n",
    "            FeatureTrain[:, i] = np.var(tmp, axis = 1)\n",
    "\n",
    "        # Test Feature Extraction\n",
    "        Test = np.concatenate((Test1, Test2), axis = 2) \n",
    "        FeatureTest = np.zeros((2 * M, Test.shape[2]))\n",
    "\n",
    "        for i in range(Test.shape[2]):\n",
    "            tmp = Test[:, :, i].T\n",
    "            tmp = W.T @ tmp\n",
    "            FeatureTest[:, i] = np.var(tmp, axis = 1)\n",
    "\n",
    "        # Label Creation\n",
    "        LabelTrain = np.concatenate((np.ones(Train1.shape[2]), 2* np.ones(Train2.shape[2])))\n",
    "        LabelTest = np.concatenate((np.ones(Test1.shape[2]), 2* np.ones(Test2.shape[2])))\n",
    "\n",
    "\n",
    "        # Train and Test Classifier\n",
    "        mdl = KNeighborsClassifier(n_neighbors=5)\n",
    "        # mdl = svm.SVC(kernel='linear', C = 1.0)\n",
    "\n",
    "        mdl.fit(FeatureTrain.T, LabelTrain)\n",
    "        LabelPredict = mdl.predict(FeatureTest.T)\n",
    "\n",
    "        Acc = accuracy_score(LabelTest, LabelPredict)\n",
    "        ConfMat.append(confusion_matrix(LabelTest, LabelPredict))\n",
    "        \n",
    "        Accuracy.append(Acc)\n",
    "    \n",
    "    Accuracy = np.array(Accuracy)\n",
    "    Alpha = AlphaList[np.argmax(Accuracy)]\n",
    "    ConfusionMatrix = ConfMat[np.argmax(Accuracy)]\n",
    "\n",
    "    # Print Metrics\n",
    "    print(f'Subject {key + 1}')\n",
    "    print(\"Accuracy : \", np.max(Accuracy), f' With Alpha of {Alpha}')\n",
    "    print(f\"Class 1 Accuracy : {(np.diag(ConfusionMatrix) / ConfusionMatrix.sum(axis=1))[0] * 100}\")\n",
    "    print(f\"Class 2 Accuracy : {(np.diag(ConfusionMatrix) / ConfusionMatrix.sum(axis=1))[1] * 100}\")\n",
    "    print(\"Confusion Matrix : \\n\", ConfusionMatrix)\n",
    "    print('-----------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
