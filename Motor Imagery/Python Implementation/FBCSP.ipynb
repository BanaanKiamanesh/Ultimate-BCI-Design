{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "435b9265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92c3be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Files\n",
    "def load_data(dir_path):\n",
    "    '''\n",
    "        Function to Read Data from mat Files\n",
    "    '''\n",
    "    \n",
    "    mat_files = []\n",
    "    for m in os.listdir(dir_path):\n",
    "        if m.endswith('.mat'):\n",
    "            mat_files.append(m)\n",
    "    \n",
    "    data = {}\n",
    "    for sbj, file in enumerate(mat_files):\n",
    "        file_path = os.path.join(dir_path, file)\n",
    "        mat_data = scipy.io.loadmat(file_path)\n",
    "        data[sbj] = (mat_data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c2c8b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FilterBandPass(CNT, Wn, Fs, order = 3):    \n",
    "    Wn = np.array([Wn[0] / (Fs/2), Wn[1] / (Fs/2)])\n",
    "    \n",
    "    # Filter Design\n",
    "    type = 'bandpass'\n",
    "    b, a = scipy.signal.butter(order, Wn, btype = 'bandpass')\n",
    "    \n",
    "    # Apply Filter\n",
    "    CNT = scipy.signal.filtfilt(b, a, CNT, axis = 0)\n",
    "    \n",
    "    return CNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75c74a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAR Filter for Spatial Filtering\n",
    "def CARFilter(Data):\n",
    "    M = np.mean(Data, axis = 1)\n",
    "    \n",
    "    for i in range(Data.shape[1]):\n",
    "        Data[:, i] = Data[:, i] - M\n",
    "    \n",
    "    return Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f28ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSP(Train1, Train2, m):\n",
    "    Rh = 0\n",
    "    for i in range(Train1.shape[2]):\n",
    "        Data = Train1[:, :, i]\n",
    "\n",
    "        # Normalize Data\n",
    "        M = np.mean(Data, axis = 0)\n",
    "\n",
    "        for i in range(Data.shape[0]):\n",
    "            Data[i, :] = Data[i, :] - M\n",
    "\n",
    "        # Cov Matrix Calculation\n",
    "        Rh += Data.T @ Data / np.trace(Data.T @ Data)\n",
    "\n",
    "    Rf = 0\n",
    "    for i in range(Train2.shape[2]):\n",
    "        Data = Train2[:, :, i]\n",
    "\n",
    "        # Normalize Data\n",
    "        M = np.mean(Data, axis = 0)\n",
    "\n",
    "        for i in range(Data.shape[0]):\n",
    "            Data[i, :] = Data[i, :] - M\n",
    "\n",
    "        # Cov Matrix Calculation\n",
    "        Rf += Data.T @ Data / np.trace(Data.T @ Data)\n",
    "\n",
    "\n",
    "    # Normalize Cov Matrix\n",
    "    Rf /= Train2.shape[2]\n",
    "    Rh /= Train1.shape[2]\n",
    "\n",
    "    # Eigen Value Decomposition\n",
    "    u, v = scipy.linalg.eig(Rh, Rf)\n",
    "    # u = np.real(u)\n",
    "\n",
    "    # Sort eigenvalues and eigenvectors by eigenvalues\n",
    "    sorted_indices = np.argsort(u)[::-1]  # Sort in descending order\n",
    "    u = u[sorted_indices]\n",
    "    v = v[:, sorted_indices]\n",
    "\n",
    "    Wm = list(range(m)) + list(range(v.shape[1] - m, v.shape[1]))\n",
    "    W = v[:, Wm]\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10ac64a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1\n",
      "Accuracy :  0.6\n",
      "Class 1 Accuracy : 80.0\n",
      "Class 2 Accuracy : 40.0\n",
      "Confusion Matrix : \n",
      " [[16  4]\n",
      " [12  8]]\n",
      "-----------------------------------------------------------------\n",
      "Subject 2\n",
      "Accuracy :  0.5\n",
      "Class 1 Accuracy : 15.0\n",
      "Class 2 Accuracy : 85.0\n",
      "Confusion Matrix : \n",
      " [[ 3 17]\n",
      " [ 3 17]]\n",
      "-----------------------------------------------------------------\n",
      "Subject 3\n",
      "Accuracy :  0.825\n",
      "Class 1 Accuracy : 90.0\n",
      "Class 2 Accuracy : 75.0\n",
      "Confusion Matrix : \n",
      " [[18  2]\n",
      " [ 5 15]]\n",
      "-----------------------------------------------------------------\n",
      "Subject 4\n",
      "Accuracy :  0.75\n",
      "Class 1 Accuracy : 70.0\n",
      "Class 2 Accuracy : 80.0\n",
      "Confusion Matrix : \n",
      " [[14  6]\n",
      " [ 4 16]]\n",
      "-----------------------------------------------------------------\n",
      "Subject 5\n",
      "Accuracy :  0.675\n",
      "Class 1 Accuracy : 60.0\n",
      "Class 2 Accuracy : 75.0\n",
      "Confusion Matrix : \n",
      " [[12  8]\n",
      " [ 5 15]]\n",
      "-----------------------------------------------------------------\n",
      "Subject 6\n",
      "Accuracy :  0.875\n",
      "Class 1 Accuracy : 90.0\n",
      "Class 2 Accuracy : 85.0\n",
      "Confusion Matrix : \n",
      " [[18  2]\n",
      " [ 3 17]]\n",
      "-----------------------------------------------------------------\n",
      "Subject 7\n",
      "Accuracy :  0.525\n",
      "Class 1 Accuracy : 45.0\n",
      "Class 2 Accuracy : 60.0\n",
      "Confusion Matrix : \n",
      " [[ 9 11]\n",
      " [ 8 12]]\n",
      "-----------------------------------------------------------------\n",
      "\n",
      " >>> Mean Accuracy ove All Subjects: 0.6785714285714286\n"
     ]
    }
   ],
   "source": [
    "dir_path = './Dataset'\n",
    "data = load_data(dir_path)\n",
    "np.random.seed(0)\n",
    "\n",
    "AvailbaleDataKeys = data.keys()\n",
    "# AvailbaleDataKeys = [6]\n",
    "\n",
    "AccAll = list()\n",
    "\n",
    "for key in list(AvailbaleDataKeys):\n",
    "    \n",
    "    # Read Data\n",
    "    CNT = data[key]['cnt']\n",
    "    nfo = data[key]['nfo']\n",
    "    mrk = data[key]['mrk']\n",
    "    fs = nfo['fs'][0][0][0][0]\n",
    "    Steps = 4\n",
    "    Bands = np.array([np.arange(4, 37, Steps), np.arange(8, 41, Steps)])\n",
    "#     CNT = FilterBandPass(CNT, [8, 30], fs)\n",
    "\n",
    "    for iter in range(Bands.shape[1]):\n",
    "\n",
    "        ## Filtering Data\n",
    "        cnt = FilterBandPass(CNT, Bands[:, iter], fs)\n",
    "\n",
    "        # Spatial Filtering\n",
    "        cnt = CARFilter(cnt)\n",
    "\n",
    "        # Trial Seperation\n",
    "        Ltr = 4 * fs\n",
    "        Pos = mrk['pos'][0][0][0]\n",
    "        Group = mrk['y'][0][0][0]\n",
    "\n",
    "        data1 = np.zeros((Ltr, cnt.shape[1], len(Group)//2))\n",
    "        data2 = np.zeros((Ltr, cnt.shape[1], len(Group)//2))\n",
    "        c1 = 0\n",
    "        c2 = 0\n",
    "\n",
    "        for i in range(len(Pos)):\n",
    "            Idx = range(Pos[i], Pos[i] + Ltr)\n",
    "            Trial = cnt[Idx, :]\n",
    "\n",
    "            if Group[i] == 1:\n",
    "                data1[:, :, c1] = Trial\n",
    "                c1 += 1\n",
    "            elif Group[i] == -1:\n",
    "                data2[:, :, c2] = Trial\n",
    "                c2 += 1\n",
    "\n",
    "        ## Train and Test Data Separation\n",
    "        # Index Creation\n",
    "        Div = 0.8\n",
    "        TrainIdx = np.arange(int(data1.shape[2] * Div))\n",
    "        TestIdx = np.arange(int(data1.shape[2] * Div), data1.shape[2])\n",
    "        \n",
    "        #print(TrainIdx)\n",
    "        #print(TestIdx)\n",
    "\n",
    "        # Data Seperation\n",
    "        Train1 = data1[:, :, TrainIdx]\n",
    "        Train2 = data2[:, :, TrainIdx]\n",
    "\n",
    "        Test1 = data1[:, :, TestIdx]\n",
    "        Test2 = data2[:, :, TestIdx]\n",
    "\n",
    "        # CSP Weight Matrix Creation\n",
    "        M = 2\n",
    "        W = CSP(Train1, Train2, M)\n",
    "\n",
    "\n",
    "        # Train Feature Extraction\n",
    "        Train = np.concatenate((Train1, Train2), axis = 2)    \n",
    "        FeatureTrain = np.zeros((2 * M, Train.shape[2]))\n",
    "\n",
    "        for i in range(Train.shape[2]):\n",
    "            tmp = Train[:, :, i].T\n",
    "            tmp = W.T @ tmp\n",
    "            FeatureTrain[:, i] = np.var(tmp, axis = 1)\n",
    "\n",
    "        # Test Feature Extraction\n",
    "        Test = np.concatenate((Test1, Test2), axis = 2) \n",
    "        FeatureTest = np.zeros((2 * M, Test.shape[2]))\n",
    "\n",
    "        for i in range(Test.shape[2]):\n",
    "            tmp = Test[:, :, i].T\n",
    "            tmp = W.T @ tmp\n",
    "            FeatureTest[:, i] = np.var(tmp, axis = 1)\n",
    "        \n",
    "        if iter == 0:\n",
    "            FTrain = FeatureTrain\n",
    "            FTest = FeatureTest \n",
    "        else:\n",
    "            FTrain = np.append(FTrain, FeatureTrain, axis = 0)\n",
    "            FTest = np.append(FTest, FeatureTest, axis = 0) \n",
    "\n",
    "\n",
    "    # Label Creation\n",
    "    LabelTrain = np.concatenate((np.ones(Train1.shape[2]), 2* np.ones(Train2.shape[2])))\n",
    "    LabelTest = np.concatenate((np.ones(Test1.shape[2]), 2* np.ones(Test2.shape[2])))\n",
    "    \n",
    "    # Feature Selection Using Fishers Discriminant Ratio\n",
    "    FDR = np.zeros(FTrain.shape[0])\n",
    "\n",
    "    for k in range(FDR.size):\n",
    "        M1 = np.mean(FTrain[k, :80])\n",
    "        M2 = np.mean(FTrain[k, 80:])\n",
    "        V1 = np.var(FTrain[k, :80])\n",
    "        V2 = np.var(FTrain[k, 80:])\n",
    "\n",
    "        FDR[k] = (M1 - M2)**2 / (V1 + V2)\n",
    "\n",
    "    # Number of Features\n",
    "    NumF = 6\n",
    "    Idx = (-FDR).argsort()[:NumF]\n",
    "    \n",
    "    # Filter Data\n",
    "    FTrain = FTrain[Idx, :]\n",
    "    FTest = FTest[Idx, :]\n",
    "    \n",
    "    # Train and Test Classifier\n",
    "    mdl = KNeighborsClassifier(n_neighbors=5, n_jobs=4)\n",
    "    # mdl = svm.SVC(kernel='linear', C = 1.0)\n",
    "\n",
    "    mdl.fit(FTrain.T, LabelTrain)\n",
    "    LabelPredict = mdl.predict(FTest.T)\n",
    "\n",
    "    Acc = accuracy_score(LabelTest.T, LabelPredict)\n",
    "    AccAll.append(Acc)\n",
    "\n",
    "    ConfMat = confusion_matrix(LabelTest, LabelPredict)\n",
    "    \n",
    "    # Print Metrics\n",
    "    print(f'Subject {key + 1}')\n",
    "    print(\"Accuracy : \", accuracy_score(LabelTest, LabelPredict))\n",
    "    print(f\"Class 1 Accuracy : {(np.diag(ConfMat) / ConfMat.sum(axis=1))[0] * 100}\")\n",
    "    print(f\"Class 2 Accuracy : {(np.diag(ConfMat) / ConfMat.sum(axis=1))[1] * 100}\")\n",
    "    print(\"Confusion Matrix : \\n\", ConfMat)\n",
    "    print('-----------------------------------------------------------------')\n",
    "    \n",
    "print(f\"\\n >>> Mean Accuracy ove All Subjects: {np.mean(AccAll)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
