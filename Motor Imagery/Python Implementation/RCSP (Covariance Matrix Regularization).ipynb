{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "435b9265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92c3be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Files\n",
    "def load_data(dir_path):\n",
    "    '''\n",
    "        Function to Read Data from mat Files\n",
    "    '''\n",
    "    \n",
    "    mat_files = []\n",
    "    for m in os.listdir(dir_path):\n",
    "        if m.endswith('.mat'):\n",
    "            mat_files.append(m)\n",
    "    \n",
    "    data = {}\n",
    "    for sbj, file in enumerate(mat_files):\n",
    "        file_path = os.path.join(dir_path, file)\n",
    "        mat_data = scipy.io.loadmat(file_path)\n",
    "        data[sbj] = (mat_data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c2c8b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FilterBandPass(CNT, Wn, Fs):    \n",
    "    Wn = np.array([Wn[0] / (Fs/2), Wn[1] / (Fs/2)])\n",
    "    \n",
    "    # Filter Design\n",
    "    order = 3\n",
    "    type = 'bandpass'\n",
    "    b, a = scipy.signal.butter(order, Wn, btype = 'bandpass')\n",
    "    \n",
    "    # Apply Filter\n",
    "    CNT = scipy.signal.filtfilt(b, a, CNT, axis = 0)\n",
    "    \n",
    "    return CNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75c74a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAR Filter for Spatial Filtering\n",
    "def CARFilter(Data):\n",
    "    M = np.mean(Data, axis = 1)\n",
    "    \n",
    "    for i in range(Data.shape[1]):\n",
    "        Data[:, i] = Data[:, i] - M\n",
    "    \n",
    "    return Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f28ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RCSP(Train1, Train2, m, Alpha, Beta, Gamma, Gc1, Gc2, Sc1, Sc2, SbjNum):\n",
    "    Rh = 0\n",
    "    for i in range(Train1.shape[2]):\n",
    "        Data = Train1[:, :, i]\n",
    "\n",
    "        # Normalize Data\n",
    "        M = np.mean(Data, axis = 0)\n",
    "\n",
    "        for i in range(Data.shape[0]):\n",
    "            Data[i, :] = Data[i, :] - M\n",
    "\n",
    "        # Cov Matrix Calculation\n",
    "        Rh += Data.T @ Data / np.trace(Data.T @ Data)\n",
    "\n",
    "    Rf = 0\n",
    "    for i in range(Train2.shape[2]):\n",
    "        Data = Train2[:, :, i]\n",
    "\n",
    "        # Normalize Data\n",
    "        M = np.mean(Data, axis = 0)\n",
    "\n",
    "        for i in range(Data.shape[0]):\n",
    "            Data[i, :] = Data[i, :] - M\n",
    "\n",
    "        # Cov Matrix Calculation\n",
    "        Rf += Data.T @ Data / np.trace(Data.T @ Data)\n",
    "\n",
    "\n",
    "    # Normalize Cov Matrix\n",
    "    Rf /= Train2.shape[2]\n",
    "    Rh /= Train1.shape[2]\n",
    "    \n",
    "    C_hat1 = (1 - Beta) * Sc1[SbjNum] * Rh + Beta * Gc1[:, :, SbjNum]\n",
    "    C_hat2 = (1 - Beta) * Sc2[SbjNum] * Rf + Beta * Gc2[:, :, SbjNum]\n",
    "    \n",
    "    C_Not1 = (1 - Gamma) * C_hat1 + Gamma * np.identity(Rf.shape[0])\n",
    "    C_Not2 = (1 - Gamma) * C_hat2 + Gamma * np.identity(Rf.shape[0])\n",
    "    \n",
    "    \n",
    "    R1 = C_Not1 + Alpha * np.identity(Rh.shape[0])\n",
    "    R2 = C_Not2 + Alpha * np.identity(Rh.shape[0])\n",
    "    \n",
    "    # Eigen Value Decomposition\n",
    "    u1, v1 = scipy.linalg.eig(C_Not1, R2)\n",
    "    # u = np.real(u)\n",
    "    \n",
    "    # Sort eigenvalues and eigenvectors by eigenvalues\n",
    "    sorted_indices = np.argsort(u1)[::-1]  # Sort in descending order\n",
    "    u1 = u1[sorted_indices]\n",
    "    v1 = v1[:, sorted_indices]\n",
    "    \n",
    "    \n",
    "    # Eigen Value Decomposition\n",
    "    u2, v2 = scipy.linalg.eig(C_Not2, R1)\n",
    "    # u = np.real(u)\n",
    "    \n",
    "    # Sort eigenvalues and eigenvectors by eigenvalues\n",
    "    sorted_indices = np.argsort(u2)[::-1]  # Sort in descending order\n",
    "    u2 = u2[sorted_indices]\n",
    "    v2 = v2[:, sorted_indices]\n",
    "    \n",
    "    W = np.concatenate((v1[:, :m], v2[:, :m]), axis = 1)\n",
    "\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84673988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cov(Train1, Train2):\n",
    "    C1 = 0\n",
    "    for i in range(Train1.shape[2]):\n",
    "        Data = Train1[:, :, i]\n",
    "\n",
    "        # Normalize Data\n",
    "        M = np.mean(Data, axis = 0)\n",
    "\n",
    "        for i in range(Data.shape[0]):\n",
    "            Data[i, :] = Data[i, :] - M\n",
    "\n",
    "        # Cov Matrix Calculation\n",
    "        C1 += Data.T @ Data / np.trace(Data.T @ Data)\n",
    "\n",
    "    C2 = 0\n",
    "    for i in range(Train2.shape[2]):\n",
    "        Data = Train2[:, :, i]\n",
    "\n",
    "        # Normalize Data\n",
    "        M = np.mean(Data, axis = 0)\n",
    "\n",
    "        for i in range(Data.shape[0]):\n",
    "            Data[i, :] = Data[i, :] - M\n",
    "\n",
    "        # Cov Matrix Calculation\n",
    "        C2 += Data.T @ Data / np.trace(Data.T @ Data)\n",
    "\n",
    "\n",
    "    # Normalize Cov Matrix\n",
    "    C1 /= Train1.shape[2]\n",
    "    C2 /= Train2.shape[2]\n",
    "    \n",
    "    Ntr = [Train1.shape[2], Train2.shape[2]]\n",
    "    \n",
    "    return C1, C2, Ntr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4a34fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = './Dataset'\n",
    "data = load_data(dir_path)\n",
    "np.random.seed(0)\n",
    "\n",
    "AvailbaleDataKeys = data.keys()\n",
    "# AvailbaleDataKeys = [6]\n",
    "\n",
    "Ntr = []\n",
    "\n",
    "for key in list(AvailbaleDataKeys):\n",
    "    \n",
    "    # Read Data\n",
    "    cnt = data[key]['cnt']\n",
    "    nfo = data[key]['nfo']\n",
    "    mrk = data[key]['mrk']\n",
    "    fs = nfo['fs'][0][0][0][0]\n",
    "    \n",
    "    ## Filtering Data\n",
    "    cnt = FilterBandPass(cnt, [8, 30], fs)\n",
    "    \n",
    "    # Spatial Filtering\n",
    "    cnt = CARFilter(cnt)\n",
    "    \n",
    "    # Trial Seperation\n",
    "    Ltr = 4 * fs\n",
    "    Pos = mrk['pos'][0][0][0]\n",
    "    Group = mrk['y'][0][0][0]\n",
    "    \n",
    "    data1 = np.zeros((Ltr, cnt.shape[1], len(Group)//2))\n",
    "    data2 = np.zeros((Ltr, cnt.shape[1], len(Group)//2))\n",
    "    c1 = 0\n",
    "    c2 = 0\n",
    "    \n",
    "    for i in range(len(Pos)):\n",
    "        Idx = range(Pos[i], Pos[i] + Ltr)\n",
    "        Trial = cnt[Idx, :]\n",
    "        \n",
    "        if Group[i] == 1:\n",
    "            data1[:, :, c1] = Trial\n",
    "            c1 += 1\n",
    "        elif Group[i] == -1:\n",
    "            data2[:, :, c2] = Trial\n",
    "            c2 += 1\n",
    "\n",
    "            \n",
    "            \n",
    "    cov1, cov2, ntr = Cov(data1, data2)\n",
    "    \n",
    "    if key == 0:\n",
    "        Cov1 = cov1\n",
    "        Cov2 = cov2\n",
    "    else:\n",
    "        Cov1 = np.dstack((Cov1, cov1))\n",
    "        Cov2 = np.dstack((Cov2, cov2))\n",
    "    \n",
    "    Ntr.append(ntr)\n",
    "\n",
    "Ntr = np.array(Ntr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb5084dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nt1 = np.sum(Ntr[:, 0])\n",
    "Nt2 = np.sum(Ntr[:, 1])\n",
    "\n",
    "Gc1 = np.zeros(Cov1.shape)\n",
    "Gc2 = np.zeros(Cov2.shape)\n",
    "\n",
    "Sc1 = np.zeros(Cov1.shape[2])\n",
    "Sc2 = np.zeros(Cov2.shape[2])\n",
    "\n",
    "for i in range(Cov1.shape[2]):\n",
    "    Idx = np.arange(Cov1.shape[2])\n",
    "    Idx = np.delete(Idx, i)\n",
    "\n",
    "    gc1 = 0\n",
    "    gc2 = 0\n",
    "    \n",
    "    for j in Idx:\n",
    "        C1 = Cov1[:, :, j]\n",
    "        C2 = Cov2[:, :, j]\n",
    "        \n",
    "        N1 = Ntr[j, 0]\n",
    "        N2 = Ntr[j, 1]\n",
    "        \n",
    "        gc1 = gc1 + (N1 / Nt1) * C1 \n",
    "        gc2 = gc2 + (N2 / Nt2) * C2\n",
    "        \n",
    "    \n",
    "    Gc1[:, :, i] = gc1\n",
    "    Gc2[:, :, i] = gc2\n",
    "    Sc1[i] = Ntr[i, 0] / Nt1\n",
    "    Sc2[i] = Ntr[i, 1] / Nt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10ac64a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 0\n",
      "Accuracy :  0.825\n",
      "Confusion Matrix : \n",
      " [[16  4]\n",
      " [ 3 17]]\n",
      "-----------------------------------------------------------------\n",
      "Subject 1\n",
      "Accuracy :  0.675\n",
      "Confusion Matrix : \n",
      " [[16  4]\n",
      " [ 9 11]]\n",
      "-----------------------------------------------------------------\n",
      "Subject 2\n",
      "Accuracy :  0.5\n",
      "Confusion Matrix : \n",
      " [[11  9]\n",
      " [11  9]]\n",
      "-----------------------------------------------------------------\n",
      "Subject 3\n",
      "Accuracy :  0.6\n",
      "Confusion Matrix : \n",
      " [[11  9]\n",
      " [ 7 13]]\n",
      "-----------------------------------------------------------------\n",
      "Subject 4\n",
      "Accuracy :  0.925\n",
      "Confusion Matrix : \n",
      " [[17  3]\n",
      " [ 0 20]]\n",
      "-----------------------------------------------------------------\n",
      "Subject 5\n",
      "Accuracy :  0.825\n",
      "Confusion Matrix : \n",
      " [[15  5]\n",
      " [ 2 18]]\n",
      "-----------------------------------------------------------------\n",
      "Subject 6\n",
      "Accuracy :  0.825\n",
      "Confusion Matrix : \n",
      " [[14  6]\n",
      " [ 1 19]]\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dir_path = './Dataset'\n",
    "data = load_data(dir_path)\n",
    "np.random.seed(0)\n",
    "\n",
    "AvailbaleDataKeys = data.keys()\n",
    "# AvailbaleDataKeys = [6]\n",
    "\n",
    "for key in list(AvailbaleDataKeys):\n",
    "    \n",
    "    # Read Data\n",
    "    cnt = data[key]['cnt']\n",
    "    nfo = data[key]['nfo']\n",
    "    mrk = data[key]['mrk']\n",
    "    fs = nfo['fs'][0][0][0][0]\n",
    "    \n",
    "    ## Filtering Data\n",
    "    cnt = FilterBandPass(cnt, [8, 30], fs)\n",
    "    \n",
    "    # Spatial Filtering\n",
    "    cnt = CARFilter(cnt)\n",
    "    \n",
    "    # Trial Seperation\n",
    "    Ltr = 4 * fs\n",
    "    Pos = mrk['pos'][0][0][0]\n",
    "    Group = mrk['y'][0][0][0]\n",
    "    \n",
    "    data1 = np.zeros((Ltr, cnt.shape[1], len(Group)//2))\n",
    "    data2 = np.zeros((Ltr, cnt.shape[1], len(Group)//2))\n",
    "    c1 = 0\n",
    "    c2 = 0\n",
    "    \n",
    "    for i in range(len(Pos)):\n",
    "        Idx = range(Pos[i], Pos[i] + Ltr)\n",
    "        Trial = cnt[Idx, :]\n",
    "        \n",
    "        if Group[i] == 1:\n",
    "            data1[:, :, c1] = Trial\n",
    "            c1 += 1\n",
    "        elif Group[i] == -1:\n",
    "            data2[:, :, c2] = Trial\n",
    "            c2 += 1\n",
    "\n",
    "    ## Train and Test Data Separation\n",
    "    # Index Creation\n",
    "    TestDiv = 0.2\n",
    "    Idx = np.random.choice(data1.shape[2], size=int(TestDiv * data1.shape[2]), replace=False)\n",
    "    TestIdx = np.zeros(data1.shape[2], dtype=bool)\n",
    "    TestIdx[Idx] = True\n",
    "    \n",
    "    TrainIdx = ~TestIdx\n",
    "    \n",
    "    # Data Seperation\n",
    "    Train1 = data1[:, :, TrainIdx]\n",
    "    Train2 = data2[:, :, TrainIdx]\n",
    "    \n",
    "    Test1 = data1[:, :, TestIdx]\n",
    "    Test2 = data2[:, :, TestIdx]\n",
    "    \n",
    "    # CSP Weight Matrix Creation\n",
    "    M     = 2\n",
    "    Alpha = 1e-4 \n",
    "    Beta  = 1e-9\n",
    "    Gamma = 1e-8\n",
    "    \n",
    "    W = RCSP(Train1, Train2, M, Alpha, Beta, Gamma, Gc1, Gc2, Sc1, Sc2, key)\n",
    "\n",
    "    # Train Feature Extraction\n",
    "    Train = np.concatenate((Train1, Train2), axis = 2)    \n",
    "    FeatureTrain = np.zeros((2 * M, Train.shape[2]))\n",
    "    \n",
    "    for i in range(Train.shape[2]):\n",
    "        tmp = Train[:, :, i].T\n",
    "        tmp = W.T @ tmp\n",
    "        FeatureTrain[:, i] = np.var(tmp, axis = 1)\n",
    "    \n",
    "    # Test Feature Extraction\n",
    "    Test = np.concatenate((Test1, Test2), axis = 2) \n",
    "    FeatureTest = np.zeros((2 * M, Test.shape[2]))\n",
    "    \n",
    "    for i in range(Test.shape[2]):\n",
    "        tmp = Test[:, :, i].T\n",
    "        tmp = W.T @ tmp\n",
    "        FeatureTest[:, i] = np.var(tmp, axis = 1)\n",
    "        \n",
    "    # Label Creation\n",
    "    LabelTrain = np.concatenate((np.ones(Train1.shape[2]), 2 * np.ones(Train2.shape[2])))\n",
    "    LabelTest = np.concatenate((np.ones(Test1.shape[2]), 2 * np.ones(Test2.shape[2])))\n",
    "    \n",
    "    \n",
    "    # Train and Test Classifier\n",
    "    mdl = KNeighborsClassifier(n_neighbors = 5)\n",
    "    # mdl = svm.SVC(kernel='linear', C = 1.0)\n",
    "    \n",
    "    mdl.fit(FeatureTrain.T, LabelTrain)\n",
    "    LabelPredict = mdl.predict(FeatureTest.T)\n",
    "    \n",
    "    Acc = accuracy_score(LabelTest, LabelPredict)\n",
    "    \n",
    "    # Print Metrics\n",
    "    print(f'Subject {key}')\n",
    "    print(\"Accuracy : \", accuracy_score(LabelTest, LabelPredict))\n",
    "    print(\"Confusion Matrix : \\n\", confusion_matrix(LabelTest, LabelPredict))\n",
    "    print('-----------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4de15201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 1\n",
      "Mean Accurcy of All Classes :  90.0\n",
      "Parameters: Alpha = 0.00e+00, Beta = 0.00e+00, Gamma = 1.00e-09\n",
      "Class 1 Accuracy : 90.0\n",
      "Class 2 Accuracy : 90.0\n",
      "-----------------------------------------------------------------\n",
      "Subject: 2\n",
      "Mean Accurcy of All Classes :  67.5\n",
      "Parameters: Alpha = 1.00e-05, Beta = 0.00e+00, Gamma = 0.00e+00\n",
      "Class 1 Accuracy : 70.0\n",
      "Class 2 Accuracy : 65.0\n",
      "-----------------------------------------------------------------\n",
      "Subject: 3\n",
      "Mean Accurcy of All Classes :  75.0\n",
      "Parameters: Alpha = 0.00e+00, Beta = 1.00e-07, Gamma = 0.00e+00\n",
      "Class 1 Accuracy : 65.0\n",
      "Class 2 Accuracy : 85.0\n",
      "-----------------------------------------------------------------\n",
      "Subject: 4\n",
      "Mean Accurcy of All Classes :  82.5\n",
      "Parameters: Alpha = 0.00e+00, Beta = 1.00e-09, Gamma = 0.00e+00\n",
      "Class 1 Accuracy : 75.0\n",
      "Class 2 Accuracy : 90.0\n",
      "-----------------------------------------------------------------\n",
      "Subject: 5\n",
      "Mean Accurcy of All Classes :  92.5\n",
      "Parameters: Alpha = 1.00e-04, Beta = 0.00e+00, Gamma = 0.00e+00\n",
      "Class 1 Accuracy : 85.0\n",
      "Class 2 Accuracy : 100.0\n",
      "-----------------------------------------------------------------\n",
      "Subject: 6\n",
      "Mean Accurcy of All Classes :  92.5\n",
      "Parameters: Alpha = 1.00e-07, Beta = 0.00e+00, Gamma = 0.00e+00\n",
      "Class 1 Accuracy : 95.0\n",
      "Class 2 Accuracy : 90.0\n",
      "-----------------------------------------------------------------\n",
      "Subject: 7\n",
      "Mean Accurcy of All Classes :  87.5\n",
      "Parameters: Alpha = 1.00e-05, Beta = 0.00e+00, Gamma = 0.00e+00\n",
      "Class 1 Accuracy : 80.0\n",
      "Class 2 Accuracy : 95.0\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dir_path = './Dataset'\n",
    "data = load_data(dir_path)\n",
    "np.random.seed(0)\n",
    "\n",
    "AvailbaleDataKeys = data.keys()\n",
    "# AvailbaleDataKeys = [6]\n",
    "\n",
    "\n",
    "for key in list(AvailbaleDataKeys):\n",
    "    \n",
    "    # Read Data\n",
    "    cnt = data[key]['cnt']\n",
    "    nfo = data[key]['nfo']\n",
    "    mrk = data[key]['mrk']\n",
    "    fs = nfo['fs'][0][0][0][0]\n",
    "    \n",
    "    ## Filtering Data\n",
    "    cnt = FilterBandPass(cnt, [8, 30], fs)\n",
    "    \n",
    "    # Spatial Filtering\n",
    "    cnt = CARFilter(cnt)\n",
    "    \n",
    "    # Trial Seperation\n",
    "    Ltr = 4 * fs\n",
    "    Pos = mrk['pos'][0][0][0]\n",
    "    Group = mrk['y'][0][0][0]\n",
    "    \n",
    "    data1 = np.zeros((Ltr, cnt.shape[1], len(Group)//2))\n",
    "    data2 = np.zeros((Ltr, cnt.shape[1], len(Group)//2))\n",
    "    c1 = 0\n",
    "    c2 = 0\n",
    "    \n",
    "    for i in range(len(Pos)):\n",
    "        Idx = range(Pos[i], Pos[i] + Ltr)\n",
    "        Trial = cnt[Idx, :]\n",
    "        \n",
    "        if Group[i] == 1:\n",
    "            data1[:, :, c1] = Trial\n",
    "            c1 += 1\n",
    "        elif Group[i] == -1:\n",
    "            data2[:, :, c2] = Trial\n",
    "            c2 += 1\n",
    "\n",
    "    ## Train and Test Data Separation\n",
    "    # Index Creation\n",
    "    TestDiv = 0.2\n",
    "    Idx = np.random.choice(data1.shape[2], size=int(TestDiv * data1.shape[2]), replace=False)\n",
    "    TestIdx = np.zeros(data1.shape[2], dtype=bool)\n",
    "    TestIdx[Idx] = True\n",
    "    \n",
    "    TrainIdx = ~TestIdx\n",
    "    \n",
    "    # Data Seperation\n",
    "    Train1 = data1[:, :, TrainIdx]\n",
    "    Train2 = data2[:, :, TrainIdx]\n",
    "    \n",
    "    Test1 = data1[:, :, TestIdx]\n",
    "    Test2 = data2[:, :, TestIdx]\n",
    "    \n",
    "    # CSP Weight Matrix Creation\n",
    "    M = 2\n",
    "    \n",
    "    # Parameter Excellence Matrix Creation\n",
    "    AlphaList = [0, 10e-10, 10e-9, 10e-8, 10e-7, 10e-6, 10e-5, 10e-4, 10e-3, 10e-2, 10e-1] \n",
    "    BetaList  = [0, 10e-10, 10e-9, 10e-8] \n",
    "    GammaList = [0, 10e-10, 10e-9]\n",
    "\n",
    "    ParamEx = np.zeros((len(AlphaList) * len(BetaList) * len(GammaList), 7))\n",
    "    \n",
    "    c = 0\n",
    "    for Alpha in AlphaList:\n",
    "        for Beta in BetaList:\n",
    "            for Gamma in GammaList:\n",
    "                ParamEx[c, 0] = Alpha\n",
    "                ParamEx[c, 1] = Beta\n",
    "                ParamEx[c, 2] = Gamma\n",
    "                \n",
    "                W = RCSP(Train1, Train2, M, Alpha, Beta, Gamma, Gc1, Gc2, Sc1, Sc2, key)\n",
    "\n",
    "                # Train Feature Extraction\n",
    "                Train = np.concatenate((Train1, Train2), axis = 2)    \n",
    "                FeatureTrain = np.zeros((2 * M, Train.shape[2]))\n",
    "\n",
    "                for i in range(Train.shape[2]):\n",
    "                    tmp = Train[:, :, i].T\n",
    "                    tmp = W.T @ tmp\n",
    "                    FeatureTrain[:, i] = np.var(tmp, axis = 1)\n",
    "\n",
    "                # Test Feature Extraction\n",
    "                Test = np.concatenate((Test1, Test2), axis = 2) \n",
    "                FeatureTest = np.zeros((2 * M, Test.shape[2]))\n",
    "\n",
    "                for i in range(Test.shape[2]):\n",
    "                    tmp = Test[:, :, i].T\n",
    "                    tmp = W.T @ tmp\n",
    "                    FeatureTest[:, i] = np.var(tmp, axis = 1)\n",
    "\n",
    "                # Label Creation\n",
    "                LabelTrain = np.concatenate((np.ones(Train1.shape[2]), 2 * np.ones(Train2.shape[2])))\n",
    "                LabelTest = np.concatenate((np.ones(Test1.shape[2]), 2 * np.ones(Test2.shape[2])))\n",
    "\n",
    "\n",
    "                # Train and Test Classifier\n",
    "                mdl = KNeighborsClassifier(n_neighbors = 5)\n",
    "                # mdl = svm.SVC(kernel='linear', C = 1.0)\n",
    "\n",
    "                mdl.fit(FeatureTrain.T, LabelTrain)\n",
    "                LabelPredict = mdl.predict(FeatureTest.T)\n",
    "\n",
    "                Acc = accuracy_score(LabelTest, LabelPredict)\n",
    "                ConfMat = confusion_matrix(LabelTest, LabelPredict)\n",
    "                \n",
    "                ParamEx[c, 3] = Acc\n",
    "                ParamEx[c, 4] = (np.diag(ConfMat) / ConfMat.sum(axis=1)).prod()\n",
    "                \n",
    "                ParamEx[c, 5] = (np.diag(ConfMat) / ConfMat.sum(axis=1))[0]\n",
    "                ParamEx[c, 6] = (np.diag(ConfMat) / ConfMat.sum(axis=1))[1]\n",
    "                c += 1\n",
    "    \n",
    "    \n",
    "    # Get the Index of Best Accuracy from the Last Column\n",
    "    BestIdx   = np.argmax(ParamEx[:, 4])\n",
    "    BestAlpha = ParamEx[BestIdx, 0]\n",
    "    BestBeta  = ParamEx[BestIdx, 1]\n",
    "    BestGamma = ParamEx[BestIdx, 2]\n",
    "    BestAcc   = ParamEx[BestIdx, 3]\n",
    "    C1BestAcc = ParamEx[BestIdx, 5]\n",
    "    C2BestAcc = ParamEx[BestIdx, 6]\n",
    "\n",
    "    # Print Metrics\n",
    "    print(f'Subject: {key + 1}')\n",
    "    print(\"Mean Accurcy of All Classes : \", BestAcc * 100)\n",
    "    print(f\"Parameters: Alpha = {BestAlpha:.2e}, Beta = {BestBeta:.2e}, Gamma = {BestGamma:.2e}\")\n",
    "    print(f\"Class 1 Accuracy : {C1BestAcc * 100}\")\n",
    "    print(f\"Class 2 Accuracy : {C2BestAcc * 100}\")\n",
    "    print('-----------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
